---
layout: page
title: research
exclude: true
---

#### *Compositional Language Modeling* ####
*Supervisor: Prof. Anand Rangarajan, University of Florida, Gainesville*

 Traditional language models treat language as a linear chain on words. In my master’s thesis I challenged this assumption and proposed a model that uses underlying compositional structure for modeling language. This is done by marginalizing the joint probability of sentence and composition tree. Conditional probability given the structure was modeled using the distributional representation and training was efficiently carried out using Inside-Outside algorithm. I also hypothesize that the phrasal and word embeddings generated by the this model can  improve upon the current state of the art for classification tasks like sentiment analysis, NER etc.

[[pdf](http://kushalarora.github.io/assets/cml_w_normalization.pdf), [code](http://github.com/kushalarora/CompositionalLM.git)]

___

#### *Contrastive Entropy: A new metric for evaluating unnormalized level language models* ####
*Supervisor: Prof. Anand Rangarajan, University of Florida, Gainesville*


Perplexity is an unsuitable metric for sentence level language models due to its word level model assumption and its reliance on exact probabilities. As part of my thesis, I also proposed a new discriminative metric to evaluate unnormalized sentence level language models. The intuition here is to capture the model’s ability to differentiate between a test sentence and its distorted version, one that is less likely to be generated by the language source. I also hypothesize that this metric will have better correlation with the WER as both metrics are discriminative in nature.

[[pdf](http://arxiv.org/pdf/1601.00248v2.pdf)]

___

#### *Sentence Level Recurrent Neural Network* ####
*Supervisor: Prof. Anand Rangarajan, University of Florida, Gainesville*


To prove the efficacy of our new metric, I reformulated RNN as a sentence level compositional model trained discriminatively to differentiate among a sentence from the training set and a slightly distorted version of it. On our new metric we reported considerable gains over RNN when this model is trained at lower level of distortion(10%).


[[pdf](http://arxiv.org/pdf/1601.00248v2.pdf), [code](http://github.com/kushalarora/sentenceRNN.git)]

____


#### *Text Extraction from an Image using Edge Information* ####
*Supervisor : Prof. Suman Mitra, DAIICT, Gandhinagar*

A novel method of marking the text areas in an image was tested. The proposed method was based on collecting the edge information first using Sobel operators and then harnessing the property of sharp edges for the text and there by marking the areas as text or non text regions.

[[pdf](/assets/text_extraction.pdf)]



