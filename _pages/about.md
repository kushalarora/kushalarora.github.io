---
layout: about
permalink: /
subtitle: <a href="https://tri.global/">Toyota Research Institute</a> • <a href="https://mila.quebec/">Mila</a> • <a href="https://www.cs.mcgill.ca/">McGill University</a>

profile:
  align: right
  image: prof_pic.jpg
  address: >

news: false  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hello!! I am Kushal Arora, a senior research scientist at [Toyota Research Institute](https://tri.global). I am working on pretraining,  scaling, and improving reasoning and instruction-following abilities of vision-language-action (VLA) models. Check out some of our recent research below. 

Before this, I was a Ph.D. student at McGill University and Mila where I was jointly supervised by Prof. [Jackie Cheung](http://cs.mcgill.ca/~jcheung/index.html) and Prof. [Doina Precup](http://www.cs.mcgill.ca/~dprecup/). I got an amazing opportunity to intern with amazing mentors at Borealis AI, Microsoft Research, and Meta AI during my Ph.D. 

<!-- My research focuses at the intersection of language modeling and reinforcement learning with the aim of building language generation models that are do not degenerate, are safe, honest, and are aligned to human preferences and values. -->

<!-- During my Ph.D. I have interned at Borealis AI with [Layla El-Asri](https://speakingmachines.com/), Microsoft Reserach with [Oriana Riva](https://www.microsoft.com/en-us/research/people/oriana/), and Meta AI (FAIR) with [Jason Weston](http://www.thespermwhale.com/jaseweston/).  -->

<!-- Before joining McGill University, I was an engineer at Amazon Alexa's Algorithms team. My work there focused on scaling distributed deep learning approaches for speech and language understanding. -->

<!-- Prior to that, I was a master student at University of Florida where I worked with Prof. [Anand Rangarajan](https://www.cise.ufl.edu/~anand/) on compositional language modeling. -->

<!-- **Research Interests**: Natural Language Generation, Reinforcement Learning, Imitation Learning, AI Safety and Alignment, Toxicity and Bias in Language Generation, and Code Generation. -->


